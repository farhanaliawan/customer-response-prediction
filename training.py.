# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b5jxIsejuqeY0Hr9AeDyTHdxoe5tkFsT
"""

pip install mlflow scikit-learn pandas numpy

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder
import mlflow
import mlflow.sklearn
import pickle
import time
import matplotlib.pyplot as plt

# Cell 2: Load the data
# Replace 'customer_data.csv' with your actual file path
data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/marketing_campaign.csv')
data.head()  # Display first few rows to verify loading

# Data preprocessing - Handle missing values
print("Missing values before handling:")
print(data.isnull().sum())

# Fill missing income values with median
data['Income'] = data['Income'].fillna(data['Income'].median())

print("\nMissing values after handling:")
print(data.isnull().sum())

# Feature engineering
# Convert birth year to age (assuming current year is 2023)
data['Age'] = 2023 - data['Year_Birth']

# Calculate total spending across all categories
data['Total_Spending'] = data[['MntWines', 'MntFruits', 'MntMeatProducts',
                              'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']].sum(axis=1)

# Calculate total children at home
data['Total_Children'] = data['Kidhome'] + data['Teenhome']

# Calculate total purchases across all channels
data['Total_Purchases'] = data[['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']].sum(axis=1)

# Display the new features
data[['Age', 'Total_Spending', 'Total_Children', 'Total_Purchases']].head()

# Encode categorical variables
label_encoders = {}
categorical_cols = ['Education', 'Marital_Status']

for col in categorical_cols:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le
    print(f"{col} classes:", le.classes_)
    print(f"{col} encoded values:", le.transform(le.classes_))

# Select features and target
features = ['Age', 'Education', 'Marital_Status', 'Income', 'Total_Children',
            'Recency', 'Total_Spending', 'Total_Purchases', 'NumWebVisitsMonth']
X = data[features]
y = data['Response']

print("Feature shapes:", X.shape, y.shape)

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("Training set size:", X_train.shape[0])
print("Test set size:", X_test.shape[0])

# Cell 8: Set up MLflow experiment
mlflow.set_experiment("Customer_Response_Prediction")

# Start MLflow run
with mlflow.start_run():
    # Cell 9: Train Random Forest model
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=5,
        random_state=42
    )
    start_time = time.time()  # Start timing
    model.fit(X_train, y_train)
    training_time = time.time() - start_time  # Calculate duration
     # Cell 10: Make predictions
    y_pred = model.predict(X_test)

    # Cell 11: Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print(f"Accuracy: {accuracy:.2f}")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"F1 Score: {f1:.2f}")
    print(f"Training Time: {training_time:.2f} seconds")

    # Cell 12: Log parameters and metrics to MLflow
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 5)
    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("precision", precision)
    mlflow.log_metric("recall", recall)
    mlflow.log_metric("f1_score", f1)
    mlflow.log_metric("training_time", training_time)  # Log training time

    # Cell 13: Log model
    mlflow.sklearn.log_model(model, "random_forest_model")

# Cell 14: Save model and label encoders locally
with open('Model.pkl', 'wb') as f:
    pickle.dump(model, f)

with open('Label_encoders.pkl', 'wb') as f:
    pickle.dump(label_encoders, f)

print("Model and label encoders saved successfully")

# Cell 15: Feature importance analysis (optional)
feature_importances = pd.Series(model.feature_importances_, index=features)
feature_importances.sort_values(ascending=False, inplace=True)

plt.figure(figsize=(10, 6))
feature_importances.plot(kind='barh')
plt.title("Feature Importances")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.show()

